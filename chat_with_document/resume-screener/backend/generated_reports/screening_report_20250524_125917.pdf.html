
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Resume Screening Report</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            color: #333;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #2980b9;
            margin-top: 20px;
        }
        .summary {
            background-color: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
        }
        .candidate {
            border: 1px solid #ddd;
            padding: 15px;
            margin-bottom: 20px;
            border-radius: 5px;
        }
        .candidate-header {
            display: flex;
            justify-content: space-between;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
            margin-bottom: 10px;
        }
        .score {
            font-size: 18px;
            font-weight: bold;
        }
        .score-high {
            color: #27ae60;
        }
        .score-medium {
            color: #f39c12;
        }
        .score-low {
            color: #e74c3c;
        }
        .requirement {
            margin: 10px 0;
        }
        .matched {
            color: #27ae60;
        }
        .not-matched {
            color: #e74c3c;
        }
        .contact-info {
            background-color: #eaf2f8;
            padding: 10px;
            border-radius: 5px;
            margin-top: 10px;
        }
        .explanation {
            font-style: italic;
            color: #7f8c8d;
            margin-left: 20px;
        }
        .timestamp {
            color: #7f8c8d;
            font-size: 12px;
            text-align: right;
            margin-top: 30px;
        }
    </style>
</head>
<body>
    <h1>Resume Screening Report</h1>
    
    <div class="summary">
        <h2>Job Description</h2>
        <p>JOB DESCRIPTION:
 
Experience in Pyspark Architecture and Performance tunning ( Problem Solving approach ) and how to get particular feedback dataset
 
Concept of Spark's Catalyst Optimizer
 
• Python • Spark (PySpark) • Jupyter • SQL and No-SQL DBMS • Git (as source code versioning and...</p>
    </div>
    
    <h2>Screening Results (3 candidates)</h2>
    
    
    <div class="candidate">
        <div class="candidate-header">
            <h3>Pyspark_ShivaniJangam_Resume_ValueLabs.docx</h3>
            
                <div class="score score-high">Match Score: 0.98</div>
            
        </div>
        
        <div class="summary">
            <h4>Summary</h4>
            <p>**Overall Assessment:**
The candidate, Shivani Jangam, appears to be a strong fit for the role, with extensive experience in big data engineering and analysis. Her background in Hadoop, Spark, and Scala, along with her experience in data warehousing and ETL tools, aligns well with the job requirements.

**Key Relevant Skills Found in Resume:**
- Hadoop Framework: Apache Hadoop, Hive, HDFS
- Spark: Scala, Spark job optimization, and performance tuning
- ETL Tools: Informatica PowerCenter, PowerCenter Navigator

**Experience Highlights & Years:**
The candidate has around 8 years of professional experience, with a focus on big data technologies. She has experience in data engineering and analysis, with specific projects highlighting her skills in data modeling, ETL development, and performance optimization.

**Strengths:**
- Strong background in big data technologies, including Hadoop, Spark, and Scala
- Experience in data engineering and analysis, with a focus on performance optimization and data modeling
- Proven ability to work with cross-functional teams and manage projects from requirement gathering to implementation

**Potential Gaps or Areas for Clarification:**
- The candidate's experience with PySpark is not explicitly mentioned, although she has worked with Spark and Scala; clarification on her PySpark skills would be beneficial
- The resume does not provide detailed information on her knowledge of Apache Airflow/Jenkins scheduling and automation, which is a key job requirement; further clarification is needed to assess her skills in this area.</p>
        </div>
        
        
        <div class="contact-info">
            <h4>Contact Information</h4>
            
                <p><strong>Email:</strong> jangamshivani@gmail.com</p>
            
            
                <p><strong>Phone:</strong> 8087851562</p>
            
        </div>
        
        
        <h4>Requirements Analysis</h4>
        
        <div class="requirement">
            <strong>Python • Spark (PySpark) • Jupyter • SQL and No-SQL DBMS • Git (as source code versioning and CI/CD) • Exploratory Data Analysis (EDA) • Imputation Techniques • Data Linking / Cleansing • Feature Engineering • Apache Airflow/ Jenkins scheduling and automation, Github and Github Actions • Python (capabilities to write unit tests) • Previous production experience is MUST in tuning and deploying the data pipelines to production • Spark job optimization (performance tuning)</strong>
            
                <span class="matched"> ✓ Matched</span>
            
            <div class="explanation">The candidate's proficiency in "Python • Spark (PySpark) • Jupyter • SQL and No-SQL DBMS • Git (as source code versioning and CI/CD) • Exploratory...</div>
        </div>
        
    </div>
    
    <div class="candidate">
        <div class="candidate-header">
            <h3>Pyspark_Data Engineer _ Gattu.Navaneeth Rao-Resume-ValueLabs.pdf</h3>
            
                <div class="score score-high">Match Score: 0.98</div>
            
        </div>
        
        <div class="summary">
            <h4>Summary</h4>
            <p>**Overall Assessment:**
The candidate, Gattu Navaneeth Rao, appears to be a strong fit for the role, with a diverse range of skills and experiences that align with the job description. The candidate's experience in Azure data services, Talend, and Apache Hadoop frameworks, as well as their proficiency in Python, Spark, and data engineering, suggest a high level of suitability for the position.

**Key Relevant Skills Found in Resume:**
- Python
- Spark (PySpark)
- Azure Data Factory (ADF)
- Data Engineering
- Apache Hadoop frameworks

**Experience Highlights & Years:**
The candidate has approximately 5.5 years of IT experience, with 4.4 years of experience in Azure data services and Talend. The resume highlights specific projects, such as EDWD, HPI-Tera Restatement, and SDM, which demonstrate the candidate's experience in data engineering, data governance, and data transformation.

**Strengths:**
- The candidate's proficiency in Python, Spark, and Azure Data Factory, which are key requirements for the role.
- The candidate's experience in data engineering, data governance, and data transformation, which aligns with the job description.
- The candidate's ability to adapt quickly to new technologies, which is essential in a rapidly evolving industry.

**Potential Gaps or Areas for Clarification:**
- The candidate's experience in Spark job optimization (performance tuning) is not explicitly mentioned in the resume, which may require clarification during an interview.
- The candidate's experience in Cloudera Data Platform (CDP) components, such as Cloudera Manager, Hive, Impala, HDFS, and HBase, is not explicitly mentioned in the resume, which may require clarification during an interview.</p>
        </div>
        
        
        <div class="contact-info">
            <h4>Contact Information</h4>
            
            
                <p><strong>Phone:</strong> 7306389971</p>
            
        </div>
        
        
        <h4>Requirements Analysis</h4>
        
        <div class="requirement">
            <strong>Python • Spark (PySpark) • Jupyter • SQL and No-SQL DBMS • Git (as source code versioning and CI/CD) • Exploratory Data Analysis (EDA) • Imputation Techniques • Data Linking / Cleansing • Feature Engineering • Apache Airflow/ Jenkins scheduling and automation, Github and Github Actions • Python (capabilities to write unit tests) • Previous production experience is MUST in tuning and deploying the data pipelines to production • Spark job optimization (performance tuning)</strong>
            
                <span class="matched"> ✓ Matched</span>
            
            <div class="explanation">The candidate's resume demonstrates a strong match with the job requirement. Specifically:

* "PySpark" is listed in Project #1, which directly...</div>
        </div>
        
    </div>
    
    <div class="candidate">
        <div class="candidate-header">
            <h3>Pyspark _Data Engineer _Resume _SE__SANDEEP BHASKARUNI _ValueLabs.docx</h3>
            
                <div class="score score-high">Match Score: 0.98</div>
            
        </div>
        
        <div class="summary">
            <h4>Summary</h4>
            <p>**Overall Assessment:**
The candidate, Sandeep Bhaskaruni, appears to be a strong fit for the role, with a comprehensive background in Big Data Ecosystems, and Agile methodologies. His experience in PySpark, Cloudera Data Platform, and Apache Airflow aligns with the job requirements.

**Key Relevant Skills Found in Resume:**
- PySpark and Spark job optimization (performance tuning)
- Cloudera Data Platform (CDP) components, including Cloudera Manager, Hive, Impala, HDFS, and HBase
- Apache Airflow and Jenkins scheduling and automation

**Experience Highlights & Years:**
The candidate has around 8.2 years of experience, including 5 years of experience in Agile Technical Scrum Lead and project management, and 4.0 years of experience in Big Data Ecosystem. His experience in handling large teams, client collaboration, and data pipeline implementation is notable.

**Strengths:**
- Strong experience in Big Data Ecosystems, including Cloudera Data Platform and Apache Airflow
- Proficient in Agile methodologies, with experience in Scrum Master certification and Agile program management
- Ability to work effectively in a multi-cultural team and individually, as per project requirements

**Potential Gaps or Areas for Clarification:**
- Although the candidate has experience in PySpark, the resume lacks specific examples of PySpark architecture and performance tuning projects.
- The candidate's experience in data warehousing and ETL tools, such as Informatica Cloud, Power BI, and Sql Database, is mentioned but not elaborated upon.</p>
        </div>
        
        
        <div class="contact-info">
            <h4>Contact Information</h4>
            
                <p><strong>Email:</strong> sndpbhaskaruni@gmail.com</p>
            
            
                <p><strong>Phone:</strong> 8886777516</p>
            
        </div>
        
        
        <h4>Requirements Analysis</h4>
        
        <div class="requirement">
            <strong>Python • Spark (PySpark) • Jupyter • SQL and No-SQL DBMS • Git (as source code versioning and CI/CD) • Exploratory Data Analysis (EDA) • Imputation Techniques • Data Linking / Cleansing • Feature Engineering • Apache Airflow/ Jenkins scheduling and automation, Github and Github Actions • Python (capabilities to write unit tests) • Previous production experience is MUST in tuning and deploying the data pipelines to production • Spark job optimization (performance tuning)</strong>
            
                <span class="matched"> ✓ Matched</span>
            
            <div class="explanation">The candidate's resume lists "Python" and "PySpark" which directly matches the job requirement. Additionally, the candidate has experience with...</div>
        </div>
        
    </div>
    
    
    <div class="timestamp">
        Report generated on 2025-05-24 12:59:17
    </div>
</body>
</html>